.nh
.TH "DBBACKUP" "1" "Feb 2026" "dbbackup" "Database Backup Tool"

.SH NAME
dbbackup-blob-backup - Backup BLOBs using parallel pipeline matrix


.SH SYNOPSIS
\fBdbbackup blob backup [flags]\fP


.SH DESCRIPTION
Backup Large Objects and BYTEA columns using the BLOB Pipeline Matrix.

.PP
Strategy selection is automatic based on BLOB size distribution:
  - Small BLOBs (1MB):   Parallel streamed via pgx Large Objects API
  - Medium BLOBs:         Standard backup via COPY protocol

.PP
Output is a tar archive containing:
  - lo\fImanifest.json: Metadata about all backed-up BLOBs
  - pack\fP\fI\&.blob:      Compressed BLOB packs (bundled small BLOBs)
  - stream_\fP\&.blob:    Individual large BLOBs (zstd compressed)
  - bytea_*.copy:     BYTEA column data (COPY format)

.PP
Examples:
  dbbackup blob backup -o /backups/blobs.tar
  dbbackup blob backup -o /backups/blobs.tar --workers 16
  dbbackup blob backup -o /backups/blobs.tar --bundle-size 2048


.SH OPTIONS
\fB--bundle-size\fP=1024
	BLOBs per pack for bundling

.PP
\fB--compress-mode\fP="auto"
	BLOB compression mode: auto, always, never

.PP
\fB--dedup\fP[=false]
	Enable content-addressed BLOB deduplication

.PP
\fB--dedup-expected\fP=5000000
	Expected BLOB count for bloom filter sizing

.PP
\fB--detect-types\fP[=true]
	Detect BLOB content types (magic bytes + entropy)

.PP
\fB-h\fP, \fB--help\fP[=false]
	help for backup

.PP
\fB-o\fP, \fB--output\fP=""
	Output file path for blob archive (required)

.PP
\fB--skip-compress-images\fP[=true]
	Skip compressing pre-compressed formats (JPEG, PNG, MP4, etc.)

.PP
\fB--split\fP[=false]
	Split backup: schema + data + BLOBs in separate files

.PP
\fB--streams\fP=4
	Number of parallel BLOB streams in split mode

.PP
\fB--threshold\fP=1048576
	BLOB size threshold for split streams (bytes)

.PP
\fB--workers\fP=8
	Number of parallel workers


.SH OPTIONS INHERITED FROM PARENT COMMANDS
\fB--allow-root\fP[=false]
	Allow running as root/Administrator

.PP
\fB--auto-detect-cores\fP[=true]
	Auto-detect CPU cores

.PP
\fB--backup-dir\fP="/root/db_backups"
	Backup directory

.PP
\fB--check-resources\fP[=true]
	Check system resource limits

.PP
\fB--compression\fP=6
	Compression level (0-9)

.PP
\fB-c\fP, \fB--config\fP=""
	Path to config file (default: .dbbackup.conf in current directory)

.PP
\fB--cpu-workload\fP="balanced"
	CPU workload type (cpu-intensive|io-intensive|balanced)

.PP
\fB--database\fP="postgres"
	Database name

.PP
\fB-d\fP, \fB--db-type\fP="postgres"
	Database type (postgres|mysql|mariadb)

.PP
\fB--debug\fP[=false]
	Enable debug logging

.PP
\fB--debug-locks\fP[=false]
	Enable detailed lock debugging (captures PostgreSQL lock configuration, Large DB Guard decisions, boost attempts)

.PP
\fB--dump-jobs\fP=8
	Number of parallel dump jobs

.PP
\fB--fallback-tools\fP[=true]
	Fallback to external tools if native engine fails

.PP
\fB--host\fP="localhost"
	Database host

.PP
\fB--insecure\fP[=false]
	Disable SSL (shortcut for --ssl-mode=disable)

.PP
\fB--jobs\fP=16
	Number of parallel jobs

.PP
\fB--max-cores\fP=32
	Maximum CPU cores to use

.PP
\fB--max-retries\fP=3
	Maximum connection retry attempts

.PP
\fB--min-backups\fP=5
	Minimum number of backups to keep

.PP
\fB--native\fP[=true]
	Use pure Go native engines (no external tools)

.PP
\fB--native-debug\fP[=false]
	Enable detailed native engine debugging

.PP
\fB--native-engine\fP[=true]
	Use pure Go native engines (alias for --native)

.PP
\fB--no-color\fP[=false]
	Disable colored output

.PP
\fB--no-config\fP[=false]
	Don't load configuration from .dbbackup.conf

.PP
\fB--no-save-config\fP[=false]
	Don't save configuration after successful operations

.PP
\fB--port\fP=5432
	Database port

.PP
\fB--retention-days\fP=30
	Backup retention period in days (0=disabled)

.PP
\fB--socket\fP=""
	Unix socket path for MySQL/MariaDB (e.g., /var/run/mysqld/mysqld.sock)

.PP
\fB--ssl-mode\fP="prefer"
	SSL mode for connections

.PP
\fB--user\fP="postgres"
	Database user


.SH SEE ALSO
\fBdbbackup-blob(1)\fP


.SH HISTORY
13-Feb-2026 Auto generated by spf13/cobra
